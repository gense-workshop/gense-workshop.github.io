---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home
title: GenSE 2025
permalink: /
---

# 2nd Workshop on Generative and Neurosymbolic AI in Software Engineering (GenSE 2025)

<center><font size="5"><b>February 24-25 2025, Karlsruhe Institute of Technology, Germany </b></font></center>

<p></p>
<h3><b>Important dates</b></h3>
- Paper submission: <s>October 28 2024 (AoE)</s> <font color="red"><b>Deadline extension: November 4 2024 (AoE)</b></font>
- Author notifications: November 28 2024 (AoE)  
- Camera-ready version: December 9 2024 (AoE)  
- Workshop: February 24-25 2025


## Motivation

Generative methods have significantly shaped the field of Artificial Intelligence (AI), starting with the release of [ChatGPT](https://chatgpt.com), followed by [GPT-4](https://arxiv.org/abs/2303.08774), and extending to open-source models like [Llama-3](https://arxiv.org/abs/2407.21783). Many of these developments stem from [advancements](https://arxiv.org/abs/1706.03762) in the transformer architecture. When a transformer is trained with a large amount of textual or multi-modal data, which can result in models with millions of parameters, it is referred to as a Large Language Model (LLM). Although the transformer architecture and the underlying attention mechanism originated in the field of machine translation, most current applications have become popular as chatbots. These applications have also demonstrated that generative models can not only process natural language very well but also generate code in common programming languages like Python or Java (e.g., [Codex](https://arxiv.org/abs/2107.03374) or [AlphaCode](https://arxiv.org/abs/2203.07814)). The automatic generation of computer code based on a description in natural language can be considered as the first application of generative AI in software development. However, the practical use of generative models carries important risks, since the correctness and reliability of such models' outputs cannot be guaranteed. In high-risk applications like healthcare, this can have catastrophic consequences. In software development, the use of generative models may result in software bugs or security vulnerabilities. Currently, various approaches, such as [evaluation frameworks](https://arxiv.org/abs/2302.04012), integrating [tools into the LLM output](https://arxiv.org/abs/2205.12255), and [causality](https://arxiv.org/abs/2112.02505), are being investigated to prevent these problems. The combination of symbolic learning and reasoning methods with deep learning systems is referred to as [neuro-symbolic AI](https://arxiv.org/abs/2012.05876). These approaches are particularly promising when it comes to making the results of generative AI reliable and explainable by incorporating structured domain knowledge and logical reasoning methods.

## Goals of the Workshop 
The goals of this workshop are as follows: 
- to discuss current and potentially new application areas of generative AI in software engineering,
- to discuss challenges in the use of generative AI methods in software engineering, 
- to propose and validate solutions to the aforementioned risks and challenges. 

Contributions on these topics from all areas of software development are welcome, especially those where AI methods have not yet been or have not been sufficiently explored. The practical application of neuro-symbolic approaches, as previously described, is expressly encouraged. The workshop is aimed at researchers and scientists, as well as developers and practitioners from industry.

## Organisation
- [Prof.(FH) Dr. Rubén Ruiz Torrubiano](https://research.imc.ac.at/de/persons/ruben-ruiz-torrubiano), Professor (FH), [IMC Krems University of Applied Sciences](https://www.imc.ac.at/).
- Dr. Alois Haselböck, Senior Scientist, Siemens AG Österreich.
- Dr. Danilo Valerio, Senior Scientist, Siemens AG Österreich.

