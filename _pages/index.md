---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home
title: Home
permalink: /
---

# Workshop Generative und Neurosymbolische KI im Software-Engineering (GenSE 2024)

<center><font size="5"><b>27.02.2024 Johannes Kepler Universität Linz, Austria</b></font></center>

## Motivation

Generative Methoden haben die Entwicklungen im Bereich Künstliche Intelligenz (KI)
im vergangenen Jahr stark geprägt, angenfangen von der Release von ChatGPT,
über GPT-4 bis hin zu Open-Source Modellen wie Llama-2. Vieler dieser
Entwicklungen haben ihren Ursprung in derWeiterentwicklung der Transformer-Architektur. 
Wenn ein Transformer mit einer großen Menge an Daten trainiert wird, was in
Modellen mit vielen Millionen Parametern resultieren kann, spricht man von einem Large
Language Model (LLM). Obwohl die Transformer-Architektur und der zugrundeliegende
Attention-Mechanismus ihren Ursprung im Bereich von maschinellem Übersetzen hat, sind
aktuell die meisten Anwendungen als Chatbots populär geworden. Solche Anwendungen
haben auch gezeigt, dass generative Modelle nicht nur natürliche Sprache sehr gut verarbeiten
können, sondern auch Code in gängigen Programmiersprachen wie Python oder Java (wie
z.B. Codex oder AlphaCode) erzeugen können. Die automatische Generierung
von Computer-Code anhand einer Beschreibung in natürlicher Sprache kann als die erste
Anwendung von generativen Modellen in der Software-Entwicklung betrachtet werden.
Trotzdem ist aktuell die Anwendung von generativen Modellen in der Praxis mit Risiken
behaftet, da die Richtigkeit und Zuverlässigkeit der Outputs solcher Modelle nicht garantiert
werden kann. In Anwendungen mit hohem Risiko wie Gesundheit kann dies
katrastophale Folgen haben. In der Software-Entwicklung kann die Verwendung von
generativen Modellen in Softwarefehler oder Sicherheitslücken resultieren.
Aktuell werden verschiedene Ansätze wie Evaluation-Frameworks, Integration
von Tools in den LLM-Output und Kausalität erforscht, um diese
Probleme zu vermeiden. Eine Ergänzung der Deep-Learning-Systeme um symbolisch
Lern- und Schlussfolgerungsmethoden wird als neurosymbolische KI bezeichnet.
Gerade diese Ansätze sind vielversprechend, wenn es darum geht, unter Einbeziehung von
strukturiertem Domänenwissen und logischen Beweisansätzen die Resultate von generativen
KIs zuverlässig und erklärbar zu machen.

## Ziele 
Als Arbeitsziele dieses Workshops betrachten wir folgende Aspekte: (i) Herausforderungen
beim Einsatz von generativen KI-Methoden im Software-Engineering diskutieren und (ii)
Lösungsansätze zu den davor genannten Risiken und Herausforderungen vorschlagen und
validieren. Beiträge zu diesen Themen aus allen Bereichen der Software-Entwicklung sind
willkommen, insbesondere jene, bei denen KI-Methoden noch nicht bzw. nicht ausreichend
erforscht sind. Der praktische Einsatz neurosymbolischer Verfahren wie vorhin beschrieben
sind ausdrücklich erwünscht. Der Workshop richtet sich sowohl an Forscher:Innen und
Wissenschaftler:Innen als auch Entwickler:Innen und Anwender:Innen aus der Industrie.

## Organisation
- [Dr. Rubén Ruiz Torrubiano](https://www.fh-krems.ac.at/fachhochschule/team/ruben-ruiz-torrubiano/), Senior Lecturer, [IMC Krems University of Applied Sciences](https://www.fh-krems.ac.at/).
- Dr. Alois Haselböck, Senior Scientist, Siemens AG Österreich.
- Dr. Danilo Valerio, Senior Scientist, Siemens AG Österreich.

